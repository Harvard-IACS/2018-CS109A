{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://github.com/Harvard-IACS/2018-CS109A/blob/master/content/styles/iacs.png?raw=true\"> CS109A/STAT121A Introduction to Data Science \n",
    "\n",
    "\n",
    "## Lab 3:  KNN Regression, Simple Linear Regression\n",
    "\n",
    "**Harvard University**<br>\n",
    "**Fall 2018**<br>\n",
    "**Instructors:** Pavlos Protopapas and Kevin Rader<br>\n",
    "**Material Preparation:** David Sondak and Will Claybaugh\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <font color='red'> Run the cell below to properly highlight the exercises</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "<ol start=\"1\">\n",
    "  <li> Simple linear regression  </li>\n",
    "  <li> $k$-nearest neighbors</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "Overall description and goal for the lab.\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Feel comfortable with simple linear regression\n",
    "* Feel comfortable with $k$ nearest neighbors\n",
    "\n",
    "**This lab corresponds to lecture 4 and maps on to homework 2 (and beyond).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "Linear regression and its many extensions are a workhorse of the statistics and data science community, both in application and as a reference point for other models. Most of the major concepts in machine learning can be and often are discussed in terms of various linear regression models. Thus, this section will introduce you to building and fitting linear regression models and some of the process behind it, so that you can 1) fit models to data you encounter 2) experiment with different kinds of linear regression and observe their effects 3) see some of the technology that makes regression models work.\n",
    "\n",
    "\n",
    "### Linear regression with a toy dataset\n",
    "We first examine a toy problem, focusing our efforts on fitting a linear model to a small dataset with three observations.  Each observation consists of one predictor $x_i$ and one response $y_i$ for $i = 1, 2, 3$,\n",
    "\n",
    "\\begin{align*}\n",
    "(x , y) = \\{(x_1, y_1), (x_2, y_2), (x_3, y_3)\\}.\n",
    "\\end{align*}\n",
    "\n",
    "To be very concrete, let's set the values of the predictors and responses.\n",
    "\n",
    "\\begin{equation*}\n",
    "(x , y) = \\{(1, 2), (2, 2), (3, 4)\\}\n",
    "\\end{equation*}\n",
    "\n",
    "There is no line of the form $\\beta_0 + \\beta_1 x = y$ that passes through all three observations, since the data are not collinear. Thus our aim is to find the line that best fits these observations in the *least-squares sense*, as discussed in lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "* Make two numpy arrays out of this data, x_train and y_train, and put into a simple scatterplot\n",
    "* Check the dimentions of these arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) (3,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10918e128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/simple_scatterplot.py\n",
    "# Make a simple scatterplot\n",
    "x_train = np.array([1,2,3])\n",
    "y_train = np.array([2,2,4])\n",
    "plt.scatter(x_train,y_train)\n",
    "\n",
    "# check dimensions \n",
    "print(x_train.shape,y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Formulae\n",
    "Linear regression is special among the models we study beuase it can be solved explicitly. While most other models (and even some advanced versions of linear regression) must be solved itteratively, linear regression has a formula where you can simply plug in the data.\n",
    "\n",
    "For the single predictor case it is:\n",
    "    \\begin{align}\n",
    "      \\beta_1 &= \\frac{\\sum_{i=1}^n{(x_i-\\bar{x})(y_i-\\bar{y})}}{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}\\\\\n",
    "      \\beta_0 &= \\bar{y} - \\beta_1\\bar{x}\\\n",
    "    \\end{align}\n",
    "    \n",
    "Where $\\bar{y}$ and $\\bar{x}$ are the mean of the y values and the mean of the x values, respectively.\n",
    "\n",
    "\n",
    "In words, \n",
    "    \\begin{align}\n",
    "      \\text{optimal slope} &= \\frac{\\sum_{\\text{all observations}}{(\\text{x's deviation from mean})(\\text{y's deviation from mean})}}{\\sum_{\\text{all observations}}{\\text{x's squared deviation from mean}}}\\\\\n",
    "      \\text{opimal intercept} &= \\text{mean y} - \\text{optimal slope}\\cdot\\text{mean x}\\\n",
    "    \\end{align}\n",
    "\n",
    "\n",
    "In statistics:\n",
    "    \\begin{align}\n",
    "      \\beta_1 &= \\frac{Cov(x,y)}{Var(x)}\\\\\n",
    "      \\bar{y} &= \\beta_0 + \\beta_1\\bar{x}\\\n",
    "    \\end{align}\n",
    "\n",
    "From the re-aranged second equation we can see that the best-fit line  passes through $(\\bar{x},\\bar{y})$, the center of mass of the data\n",
    "\n",
    "From any of the first equations, we can see that the slope of the line has to do with whether or not an x value that is above/below the center of mass is typically paired with a y value that is likewise above/below, or typically paired with one that is opposite.\n",
    "\n",
    "Right now, the derivation of $\\beta_{0}$ and $\\beta_{1}$ is a mystery.  Don't worry about this!  You will see where they come from in lecture next week.  In this lab, you will simply implement the simple formulas for $\\beta_{0}$ and $\\beta_{1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building a model from scratch\n",
    "In this part, we will solve the equations for simple linear regression and find the best fit solution to our toy problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snippets of code below implement the linear regression equations on the observed predictors and responses, which we'll call the training data set.  Let's walk through the code.\n",
    "\n",
    "We have to reshape our arrrays to 2D. We will see later why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to be a proper 2D array\n",
    "x_train = x_train.reshape(x_train.shape[0], 1)\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, compute means\n",
    "y_bar = np.mean(y_train)\n",
    "x_bar = np.mean(x_train)\n",
    "\n",
    "# build the two terms\n",
    "numerator = np.sum( (x_train - x_bar)*(y_train - y_bar) )\n",
    "denominator = np.sum((x_train - x_bar)**2)\n",
    "\n",
    "print(numerator.shape, denominator.shape) #check shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why the empty brackets? (The numerator and denominator are scalars, as expected.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slope beta1\n",
    "beta_1 = numerator/denominator\n",
    "\n",
    "#intercept beta0\n",
    "beta_0 = y_bar - beta_1*x_bar\n",
    "\n",
    "print(\"The best-fit line is {0:8.6f} + {1:8.6f} * x\".format(beta_0, beta_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "Turn the code from the above cells into a function called `simple_linear_regression_fit`, that inputs the training data and returns `beta0` and `beta1`.\n",
    "\n",
    "To do this, copy and paste the code from the above cells below and adjust the code as needed, so that the training data becomes the input and the betas become the output.\n",
    "\n",
    "```python\n",
    "def simple_linear_regression_fit(x_train: np.ndarray, y_train: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    return\n",
    "```\n",
    "\n",
    "Check your function by calling it with the training data from above and printing out the beta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/simple_linear_regression_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's run this function and see the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([1 ,2, 3])\n",
    "y_train = np.array([2, 2, 4])\n",
    "\n",
    "betas = simple_linear_regression_fit(x_train, y_train)\n",
    "\n",
    "beta_0 = betas[0]\n",
    "beta_1 = betas[1]\n",
    "\n",
    "print(\"The best-fit line is {0:8.6f} + {1:8.6f} * x\".format(beta_0, beta_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "* Do the values of `beta0` and `beta1` seem reasonable?\n",
    "* Plot the training data using a scatter plot.\n",
    "* Plot the best fit line with `beta0` and `beta1` together with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/best_fit_scatterplot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of `beta0` and `beta1` seem roughly reasonable.  They capture the positive correlation.  The line does appear to be trying to get as close as possible to all the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Building a model with `statsmodels` and `sklearn`\n",
    "\n",
    "Now that we can concretely fit the training data from scratch, let's learn two `python` packages to do it all for us:\n",
    "* [statsmodels](http://www.statsmodels.org/stable/regression.html) and \n",
    "* [scikit-learn (sklearn)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "Our goal  is to show how to implement simple linear regression with these packages.  For an important sanity check, we compare the $\\beta$ values from `statsmodels` and `sklearn` to the $\\beta$ values that we found from above with our own implementation.\n",
    "\n",
    "For the purposes of this lab, `statsmodels` and `sklearn` do the same thing.  More generally though, `statsmodels` tends to be easier for inference \\[finding the values of the slope and intercept and dicussing uncertainty in those values\\], whereas `sklearn` has machine-learning algorithms and is better for prediction \\[guessing y values for a given x value\\]. (Note that both packages make the same guesses, it's just a question of which activity they provide more support for.\n",
    "\n",
    "**Note:** `statsmodels` and `sklearn` are different packages!  Unless we specify otherwise, you can use either one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code for `statsmodels`.  `Statsmodels` does not by default include the column of ones in the $X$ matrix, so we include it manually with `sm.add_constant`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the X matrix by appending a column of ones to x_train\n",
    "X = sm.add_constant(x_train)\n",
    "\n",
    "# this is the same matrix as in our scratch problem!\n",
    "print(X)\n",
    "\n",
    "# build the OLS model (ordinary least squares) from the training data\n",
    "toyregr_sm = sm.OLS(y_train, X)\n",
    "\n",
    "# do the fit and save regression info (parameters, etc) in results_sm\n",
    "results_sm = toyregr_sm.fit()\n",
    "\n",
    "# pull the beta parameters out from results_sm\n",
    "beta0_sm = results_sm.params[0]\n",
    "beta1_sm = results_sm.params[1]\n",
    "\n",
    "print(\"The regression coefficients from the statsmodels package are: beta_0 = {0:8.6f} and beta_1 = {1:8.6f}\".format(beta0_sm, beta1_sm))\n",
    "# print(\"(beta0, beta1) = (%f, %f)\" %(beta0_sm, beta1_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the beta parameters, `results_sm` contains a ton of other potentially useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn our attention to the `sklearn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the least squares model\n",
    "toyregr = linear_model.LinearRegression()\n",
    "\n",
    "# save regression info (parameters, etc) in results_skl\n",
    "results = toyregr.fit(x_train, y_train)\n",
    "\n",
    "# pull the beta parameters out from results_skl\n",
    "beta0_skl = toyregr.intercept_\n",
    "beta1_skl = toyregr.coef_[0]\n",
    "\n",
    "print(\"The regression coefficients from the sklearn package are: beta_0 = {0:8.6f} and beta_1 = {1:8.6f}\".format(beta0_skl, beta1_skl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should feel pretty good about ourselves now, and we're ready to move on to a real problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4:  The shape of things in `scikit-learn`\n",
    "Before diving right in to a \"real\" problem, we really ought to discuss more of the details of `sklearn`.  We do this now.  Along the way, we'll import the real-world dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-learn` is the main `python` machine learning library. It consists of many learners which can learn models from data, as well as a lot of utility functions such as `train_test_split`. It can be used in `python` by the incantation `import sklearn`.\n",
    "\n",
    "The library has a very well-defined interface. This makes the library a joy to use, and surely contributes to its popularity.  The API consists of three interfaces:\n",
    "1. estimator interface: builds and fits models\n",
    "   * This interface is at the core of the library\n",
    "   * Provides the `fit()` method\n",
    "   * Unsupervised and supervised learning algorithms can be accessed from the estimator interface\n",
    "2. predictor interface: makes predictions\n",
    "3. transformer interface: converts data\n",
    "\n",
    "You can refer to the original `scikit-learn` API paper for more details: [Buitinck, Lars, et al. \"API design for machine learning software: experiences from the scikit-learn project.\" arXiv preprint arXiv:1309.0238 (2013).]\n",
    "\n",
    "Let's see the structure of `scikit-learn` needed to make these fits. `.fit` always takes two arguments:\n",
    "```python\n",
    "  estimator.fit(Xtrain, ytrain)\n",
    "```\n",
    "We will consider two estimators in this lab: `LinearRegression` and `KNeighborsRegressor`.\n",
    "\n",
    "Critically, `Xtrain` must be in the form of an *array of arrays*, with the inner arrays each corresponding to one sample, and whose elements correspond to the feature values for that sample (visuals coming in a moment).\n",
    "\n",
    "`ytrain` on the other hand is a simple array of responses.  These are continuous for regression problems.\n",
    "\n",
    "![](images/sklearn2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice with `sklearn`\n",
    "We begin by loading up the `mtcars` dataset and cleaning it up a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load mtcars\n",
    "dfcars = pd.read_csv(\"data/mtcars.csv\")\n",
    "dfcars = dfcars.rename(columns={\"Unnamed: 0\":\"car name\"})\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split the dataset into a training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#set random_state to get the same split every time\n",
    "traindf, testdf = train_test_split(dfcars, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing set is around 20% of the total data; training set is around 80%\n",
    "print(\"Shape of full dataset is: {0}\".format(dfcars.shape))\n",
    "print(\"Shape of training dataset is: {0}\".format(traindf.shape))\n",
    "print(\"Shape of test dataset is: {0}\".format(testdf.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have training and test data.  We still need to select a predictor and a response from this dataset.  Keep in mind that we need to choose the predictor and response from both the training and test set.  You will do this in the exercises below.  However, we provide some starter code for you to get things going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the response variable that we're interested in\n",
    "y_train = traindf.mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the shape of `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to see the shape is to use the shape method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is *not* an \"array of arrays\".  That's okay!  Remember, `sklearn` requires an array of arrays only for the predictor array!  You will have to pay close attention to this in the exercises later.\n",
    "\n",
    "For now, let's discuss two ways out of this debacle.  All we'll do is get `y_train` to be an array of arrays.  This doesn't hurt anything because `sklearn` doesn't care too much about the shape of `y_train`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's reshape `y_train` to be an array of arrays using the `reshape` method.  We want the first dimension of `y_train` to be size $25$ and the second dimension to be size $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reshape = y_train.values.reshape(y_train.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reshape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `y_train.shape[0]` gives the size of the first dimension.\n",
    "\n",
    "There's an even easier way to get the correct shape right from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reshape = traindf[['mpg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reshape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there is a nice shortcut to reshaping an array.  `numpy` can infer a dimension based on the other dimensions specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reshape = y_train.values.reshape(-1,1)\n",
    "y_train_reshape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we said the second dimension should be size $1$.  Since the requirement of the `reshape()` method is that the requested dimensions be compatible, `numpy` decides the the first dimension must be size $25$.\n",
    "\n",
    "What would the `.shape` return if we did `y_train.values.reshape(-1,5)`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, enough of that.  The whole reason we went through that whole process was to show you how to reshape your data into the correct format.\n",
    "\n",
    "**IMPORTANT:** Remember that your response variable `ytrain` can be a vector but your predictor variable `xtrain` ***must*** be an array!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear regression with automobile data\n",
    "We will now use `sklearn` to predict automobile mileage per gallon (mpg) and evaluate these predictions. We already loaded the data and split them into a training set and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to choose the variables that we think will be good predictors for the dependent variable `mpg`.â€Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "* Pick one variable to use as a predictor for simple linear regression.  Create a markdown cell below and discuss your reasons.  \n",
    "* Justify your choice with some visualizations.  \n",
    "* Is there a second variable you'd like to use? For example, we're not doing multiple linear regression here, but if we were, is there another variable you'd like to include if we were using two predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/cars_simple_EDA.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "\n",
    "* Use `sklearn` to fit the training data using simple linear regression.\n",
    "* Use the model to make mpg predictions on the test set.  \n",
    "* Plot the data and the prediction.  \n",
    "* Print out the mean squared error for the training set and the test set and compare.\n",
    "\n",
    "**Hints:**\n",
    "* Use the following to perform the analysis:\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "dfcars = pd.read_csv(\"data/mtcars.csv\")\n",
    "dfcars = dfcars.rename(columns={\"Unnamed: 0\":\"name\"})\n",
    "\n",
    "dfcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf, testdf = train_test_split(dfcars, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = np.array(traindf.mpg)\n",
    "X_train = np.array(traindf.wt)\n",
    "X_train = X_train.reshape(X_train.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(testdf.mpg)\n",
    "X_test = np.array(testdf.wt)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1)\n",
    "\n",
    "#create linear model\n",
    "regression = LinearRegression()\n",
    "\n",
    "#fit linear model\n",
    "regression.fit(X_train, y_train)\n",
    "\n",
    "predicted_y = regression.predict(X_test)\n",
    "\n",
    "r2 = regression.score(X_test, y_test)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression.score(X_train, y_train))\n",
    "\n",
    "print(mean_squared_error(predicted_y, y_test))\n",
    "print(mean_squared_error(y_train, regression.predict(X_train)))\n",
    "\n",
    "print('Coefficients: \\n', regression.coef_[0], regression.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.plot(y_test, predicted_y, 'o')\n",
    "grid = np.linspace(np.min(dfcars.mpg), np.max(dfcars.mpg), 100)\n",
    "ax.plot(grid, grid, color=\"black\") # 45 degree line\n",
    "ax.set_xlabel(\"actual y\")\n",
    "ax.set_ylabel(\"predicted y\")\n",
    "\n",
    "fig1, ax1 = plt.subplots(1,1, figsize=(10,6))\n",
    "ax1.plot(dfcars.wt, dfcars.mpg, 'o')\n",
    "xgrid = np.linspace(np.min(dfcars.wt), np.max(dfcars.wt), 100)\n",
    "ax1.plot(xgrid, regression.predict(xgrid.reshape(100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4:  $k$-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we did a simple linear regression on the car data.\n",
    "\n",
    "Because we're good data scientists, we decide that a $k$ nearest-neighbor regression should also be performed.\n",
    "\n",
    "Now that you're familiar with the `sklearn` API, you're ready to do a KNN regression.  We can go a little quicker here.  Let's use $5$ nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knnreg = KNeighborsRegressor(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnreg.fit(X_train, y_train)\n",
    "r2 = knnreg.score(X_test, y_test)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "What is the $R^{2}$ score on the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "knnreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets vary the number of neighbors and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regdict = {}\n",
    "# Do a bunch of KNN regressions\n",
    "for k in [1, 2, 4, 6, 8, 10, 15]:\n",
    "    knnreg = KNeighborsRegressor(n_neighbors=k)\n",
    "    knnreg.fit(X_train, y_train)\n",
    "    regdict[k] = knnreg # Store the regressors in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's plot it all\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "ax.plot(dfcars.wt, dfcars.mpg, 'o', label=\"data\")\n",
    "\n",
    "xgrid = np.linspace(np.min(dfcars.wt), np.max(dfcars.wt), 100)\n",
    "for k in [1, 2, 6, 10, 15]:\n",
    "    predictions = regdict[k].predict(xgrid.reshape(100,1))\n",
    "    if k in [1, 6, 15]:\n",
    "        ax.plot(xgrid, predictions, label=\"{}-NN\".format(k))\n",
    "\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the $1$-NN goes through every point on the training set but utterly fails elsewhere. Lets look at the scores on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 15) # Grid of k's\n",
    "scores_train = [] # R2 scores\n",
    "for k in ks:\n",
    "    knnreg = KNeighborsRegressor(n_neighbors=k) # Create KNN model\n",
    "    knnreg.fit(X_train, y_train) # Fit the model to training data\n",
    "    score_train = knnreg.score(X_train, y_train) # Calculate R^2 score\n",
    "    scores_train.append(score_train)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.plot(ks, scores_train,'o-')\n",
    "ax.set_xlabel(r'$k$')\n",
    "ax.set_ylabel(r'$R^{2}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we get a perfect $R^2$ at k=1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise</b></div>\n",
    "* Make the same plot as above on the *test* set.\n",
    "* What is the best $k$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/knn_regression.py\n",
    "ks = range(1, 15) # Grid of k's\n",
    "scores_test = [] # R2 scores\n",
    "for k in ks:\n",
    "    knnreg = KNeighborsRegressor(n_neighbors=k) # Create KNN model\n",
    "    knnreg.fit(X_train, y_train) # Fit the model to training data\n",
    "    score_test = knnreg.score(X_test, y_test) # Calculate R^2 score\n",
    "    scores_test.append(score_test)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,8))\n",
    "ax.plot(ks, scores_test,'o-', ms=12)\n",
    "ax.set_xlabel(r'$k$')\n",
    "ax.set_ylabel(r'$R^{2}$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
