{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "InJYthzSP5BG"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science\n",
    "\n",
    "## Standard Section 3: Predictor types and Feature Selection\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors:** Pavlos Protopapas, Kevin Rader<br/>\n",
    "**Section Leaders:** Mehul Smriti Raje, Ken Arnold, Karan Motwani, Cecilia Garraffo<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RC0Gid-wP5BH",
    "outputId": "25d33127-f718-4d41-d6ec-f66a88623a38"
   },
   "outputs": [],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"http://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6j9jYbUHP5BM"
   },
   "source": [
    "For this section, our goal is to discuss the complexities around different types of data features and thinking carefully about how different datatypes and collinearity issues can affect our models, whether our true goal is inference or prediction.\n",
    "\n",
    "Specifically, we will: \n",
    "    \n",
    "    1. Discuss different variable types, and techniques of “one-hot-encoding” our factor variables \n",
    "    2. Build a variable selection function that performs an exhaustive feature search overall all possible combinations of predictors \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQ785f0zP5BN"
   },
   "source": [
    "For this section we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JfEq-JgsP5BO",
    "outputId": "f8822af7-e3c6-4363-d9ca-0538137a7862"
   },
   "outputs": [],
   "source": [
    "#Check Python Version\n",
    "import sys\n",
    "assert(sys.version_info.major==3), print(sys.version)\n",
    "\n",
    "# Data and Stats packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm # RUNNING FOR ME (MSR)\n",
    "\n",
    "# Visualization packages\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['figure.figsize'] = (13.0, 6.0)\n",
    "\n",
    "# Other Helpful fucntions\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Aesthetic settings\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.notebook_repr_html', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IhthgP5P5CH"
   },
   "source": [
    "## 1. Extending Linear Regression by Transforming Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7jCXcNmP5CI"
   },
   "source": [
    "Linear regression works great when our features are all continuous and all linearly affect the output. But often real data have more interesting characteristics. Here, we'll look at how we can extend linear regression to handle:\n",
    "\n",
    "* Categorical predictors, like gender, which have one of a few discrete values\n",
    "* Interactions between predictors, which let us model how one variable changes the effect of another.\n",
    "\n",
    "For our dataset, we'll be using the passenger list from the Titanic, which famously sank in 1912. Let's have a look at the data. Some descriptions of the data are at https://www.kaggle.com/c/titanic/data, and here's [how seaborn preprocessed it](https://github.com/mwaskom/seaborn-data/blob/master/process/titanic.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "k3N2ECgfP5CI",
    "outputId": "49829d5b-c837-47e4-b862-106ec201bb26"
   },
   "outputs": [],
   "source": [
    "# Load the dataset from seaborn \n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "N3l0V_QDXdrf"
   },
   "outputs": [],
   "source": [
    "# Keep only a subset of the predictors; some are redundant, others (like deck) have too many missing values.\n",
    "titanic = titanic[['age', 'sex', 'class', 'embark_town', 'alone', 'fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uiDggiVkRlOU",
    "outputId": "640db74c-84e5-49ad-f1fd-99ecbe1d651a"
   },
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "x2wvtyO-R59v",
    "outputId": "4c84571c-2ebf-4608-fda8-e7a4f3402049"
   },
   "outputs": [],
   "source": [
    "# Drop missing data (is this a good idea?)\n",
    "titanic = titanic.dropna()\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibT2p_BzeHwT"
   },
   "source": [
    "Let's explore this data. Most people look at differences in survival, which is important but requires knowing how to deal with categorical responses, which we'll learn how to do next week. For this week, let's see if there are systematic differences in what fare people paid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NPQpANf2eZ0Z"
   },
   "source": [
    "First let's look at the distribution of fares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 1**: Show the distribution of fares in at least two ways. You may use functions from matplotlib, Pandas, or Seaborn.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "gE1Zjgf_edU5",
    "outputId": "c0851f01-9477-4626-bb81-3dcfdb11fc51"
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fhbC0FXiZJIt",
    "outputId": "d822cc3b-9563-4513-8fe2-df26b2068696"
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdb0KU9ofkPf"
   },
   "source": [
    "What do we learn from each visualization? Which is most helpful?\n",
    "\n",
    "What can we say about the fares that passengers paid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1vgnVjXfL6B"
   },
   "source": [
    "Cabin class is probably going to matter for fare, but we might wonder if age and gender also matter. Let's explore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "zYsj6roaRLdX",
    "outputId": "7221f900-2888-4f28-f835-02d84abcb7d9"
   },
   "outputs": [],
   "source": [
    "sns.distplot(titanic.age, rug=True, rug_kws={'alpha': .1, 'color': 'k'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "gnSM0FbFSXcC",
    "outputId": "c3b4451c-92bc-4097-aa44-d5d2fd95becf"
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"fare\", hue=\"sex\", data=titanic, size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... the slopes seem to be different for males and females. Remember this for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about sex and class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic['class'].value_counts()\n",
    "# Why couldn't we write `titanic.class.value_counts()` here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SETvpblUTIfU",
    "outputId": "b9e76e3d-e8c8-4552-878b-d445969d3502"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"class\", hue=\"sex\", y=\"fare\", data=titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "NYT9sIlIhKIH",
    "outputId": "07620610-bd21-4cdc-b8d6-26fd891d8b62"
   },
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"class\", hue=\"sex\", y=\"fare\", data=titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: can we replicate that violin plot without Seaborn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.violinplot takes an array of data arrays, and plots each one as a separate violin.\n",
    "# The data arrays don't have to be the same length.\n",
    "# It returns Matplotlib objects corresponding to each of the pieces of the visualization.\n",
    "plt.violinplot([\n",
    "    [0,1,2], \n",
    "    [10, 14, 9, 10, 10, 10],\n",
    "    [6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use Pandas queries to make datasets for each class.\n",
    "# We need to use `.values` to get plain Numpy arrays.\n",
    "classes = 'First Second Third'.split()\n",
    "plt.violinplot([\n",
    "    titanic['fare'][titanic['class'] == cls].values\n",
    "    for cls in classes\n",
    "])\n",
    "plt.xticks([1,2,3], classes)\n",
    "plt.xlabel(\"Ticket Class\")\n",
    "plt.ylabel(\"Fare\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It gets a little more tricky when we want to plot the two sexes side-by-side.\n",
    "# Fortunately we can tell violinplot to place the violins at different positions.\n",
    "position_array = [0, 4, 5] # just to show the effect of the position array.\n",
    "plt.violinplot([\n",
    "    titanic['fare'][titanic['class'] == cls].values\n",
    "    for cls in classes\n",
    "], positions=position_array)\n",
    "#plt.xticks(position_array, classes)\n",
    "plt.xlabel(\"Ticket Class\")\n",
    "plt.ylabel(\"Fare\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can use the position array to shift the male and female violins.\n",
    "\n",
    "sexes = 'male female'.split()\n",
    "positions_array = np.arange(len(classes)) # this will be [0, 1, 2]\n",
    "for i, sex in enumerate(sexes):\n",
    "    offset = .15 * (-1 if i == 0 else 1)\n",
    "    violin = plt.violinplot([\n",
    "        titanic['fare'][(titanic['sex'] == sex) & (titanic['class'] == cls)].values\n",
    "        for cls in classes\n",
    "    ], positions=positions_array + offset, widths=.25, showmedians=True, showextrema=True)\n",
    "plt.xticks(positions_array, classes)\n",
    "plt.xlabel(\"Ticket Class\")\n",
    "plt.ylabel(\"Fare\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# But what about a legend? Unfortunately plt.violinplot doesn't support legends, so we\n",
    "# have to do it by hand.\n",
    "positions_array = np.arange(len(classes))\n",
    "fake_handles = []\n",
    "for i, sex in enumerate(sexes):\n",
    "    offset = .15 * (-1 if i == 0 else 1)\n",
    "    violin = plt.violinplot([\n",
    "        titanic['fare'][(titanic['sex'] == sex) & (titanic['class'] == cls)].values\n",
    "        for cls in classes\n",
    "    ], positions=positions_array + offset, widths=.25, showmedians=True, showextrema=True)\n",
    "    fake_handles.append(mpatches.Patch())\n",
    "plt.legend(fake_handles, sexes)\n",
    "plt.xticks(positions_array, classes)\n",
    "plt.xlabel(\"Ticket Class\")\n",
    "plt.ylabel(\"Fare\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dang, the colors are wrong. We'll have to use some hacky code to pull the color out of the violin...\n",
    "positions_array = np.arange(len(classes))\n",
    "fake_handles = []\n",
    "for i, sex in enumerate(sexes):\n",
    "    offset = .15 * (-1 if i == 0 else 1)\n",
    "    violin = plt.violinplot([\n",
    "        titanic['fare'][(titanic['sex'] == sex) & (titanic['class'] == cls)].values\n",
    "        for cls in classes\n",
    "    ], positions=positions_array + offset, widths=.25, showmedians=True, showextrema=True)\n",
    "    cur_violin_color = violin['cbars'].get_color()[0]\n",
    "    fake_handles.append(mpatches.Patch(color=cur_violin_color))\n",
    "plt.legend(fake_handles, sexes)\n",
    "plt.xticks(positions_array, classes)\n",
    "plt.xlabel(\"Ticket Class\")\n",
    "plt.ylabel(\"Fare\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Or explicitly control the colors.\n",
    "colors = sns.color_palette(\"Set1\", n_colors=len(sexes), desat=.5)\n",
    "sns.palplot(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions_array = np.arange(len(classes))\n",
    "fake_handles = []\n",
    "for i, sex in enumerate(sexes):\n",
    "    offset = .15 * (-1 if i == 0 else 1)\n",
    "    violin = plt.violinplot([\n",
    "        titanic['fare'][(titanic['sex'] == sex) & (titanic['class'] == cls)].values\n",
    "        for cls in classes\n",
    "    ], positions=positions_array + offset, widths=.25, showmedians=True, showextrema=True)\n",
    "\n",
    "    # Set the color\n",
    "    color = colors[i]\n",
    "    for part_name, part in violin.items():\n",
    "        if part_name == 'bodies':\n",
    "            for body in violin['bodies']:\n",
    "                body.set_color(color)\n",
    "        else:\n",
    "            part.set_color(color)\n",
    "    fake_handles.append(mpatches.Patch(color=color))\n",
    "\n",
    "plt.legend(fake_handles, sexes)\n",
    "plt.xticks(positions_array, classes)\n",
    "plt.xlabel(\"Ticket Class\")\n",
    "plt.ylabel(\"Fare\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No more digression, back to regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJK_rkcPTpD5"
   },
   "source": [
    "So it looks like fare varies with class, age, and maybe gender, and the way that fare depends on class and age may be different for male vs female.\n",
    "\n",
    "Let's first do a simple linear regression on age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JudMdrUpTpbL",
    "outputId": "3ace581b-b847-40c8-a580-b580391b8b36"
   },
   "outputs": [],
   "source": [
    "model1 = sm.OLS(\n",
    "    titanic.fare,\n",
    "    sm.add_constant(titanic['age'])\n",
    ").fit()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrHXCrJNf1xc"
   },
   "source": [
    "How do we interpret this?\n",
    "\n",
    "* How good is this model?\n",
    "* Does age affect fare? How can we tell? And if so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8eMLGl7gNlP"
   },
   "source": [
    "Statistical packages generally distinguish between three types of variables:\n",
    "\n",
    "* **continuous** variables, like age and fare.\n",
    "* **nominal** variables, like gender and whether the person survived\n",
    "* **ordinal** variables like cabin class (first > second > third)\n",
    "\n",
    "(Ordinal variables can often be treated like nominal variables; that's what we'll do for now.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESeqInU9Tnt5"
   },
   "source": [
    "How do we deal with gender, or class? They're categorical variables. We'll need to use dummy variables to encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_orig = titanic.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 2**: Create a column `sex_male` that is 1 if the passenger is male, 0 otherwise.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 3**: Do we need a `sex_female` column, or any others? Why or why not?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 4**: Create columns for `class_`</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qTxXqm6wW22a",
    "outputId": "e8f01d1a-ea5f-4711-a41f-96d92d13e507"
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**Exercise 5**: Fit a linear regression including the new sex and class variables.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZtEXD-ZWYGuT",
    "outputId": "b991b04a-5e5c-4080-b128-67b5415f8c50"
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zl3IDAtqP5Ck"
   },
   "source": [
    "<div class='exercise'> **Exercise 6** How do we interpret these results?</div>\n",
    "* All else being equal, what does being male do to the fare?\n",
    "* What can we say about being *male* and *first-class*?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "8oRObtxEYlGi",
    "outputId": "ca3661e0-6f01-4128-9ecb-cd36775ae462"
   },
   "outputs": [],
   "source": [
    "# It seemed like gender interacted with age and class. Can we put that in our model?\n",
    "titanic['sex_male_X_age'] = titanic['age'] * titanic['sex_male']\n",
    "model3 = sm.OLS(\n",
    "    titanic.fare,\n",
    "    sm.add_constant(titanic[['age', 'sex_male', 'class_Second', 'class_Third', 'sex_male_X_age']])\n",
    ").fit()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uuOUlHs5Zdxr"
   },
   "source": [
    "** What happened to the `age` and `male` terms? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "29Nbm25-ZoOj",
    "outputId": "91eb202e-6da3-4ecb-e76d-1d7a5b5a2617"
   },
   "outputs": [],
   "source": [
    "# It seemed like gender interacted with age and class. Can we put that in our model?\n",
    "titanic['sex_male_X_class_Second'] = titanic['age'] * titanic['class_Second']\n",
    "titanic['sex_male_X_class_Third'] = titanic['age'] * titanic['class_Third']\n",
    "model4 = sm.OLS(\n",
    "    titanic.fare,\n",
    "    sm.add_constant(titanic[['age', 'sex_male', 'class_Second', 'class_Third', 'sex_male_X_age', 'sex_male_X_class_Second', 'sex_male_X_class_Third']])\n",
    ").fit()\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What has happened to the $R^2$ as we added more features? Does this mean that the model is better? (What if we kept adding more predictors and interaction terms? We'll explore this in the next homework.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [model1, model2, model3, model4]\n",
    "plt.plot([model.df_model for model in models], [model.rsquared for model in models], 'x-')\n",
    "plt.xlabel(\"Model df\")\n",
    "plt.ylabel(\"$R^2$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QAno5_o3P5Dg"
   },
   "source": [
    "## 2. Model Selection via exhaustive search selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DscFfMaTP5Dg"
   },
   "source": [
    "The dataset for this problem contains 10 simulated predictors and a response variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "au6W6nZKP5Dg",
    "outputId": "ecb008c9-3c49-4f0b-ac78-1bae613227d3"
   },
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "data = pd.read_csv('data/dataset3.txt')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EV0nj6vzP5Dj"
   },
   "source": [
    "**By visually inspecting the data set, do we find that some of the predictors are correlated amongst themselves?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0CndxvVTP5Dk",
    "outputId": "000dae40-ab66-4909-bc2c-920cd9baae18"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQW6Dx9sP5Dn"
   },
   "source": [
    "Predictors x1, x2, x3 seem to be perfectly correlated while predictors x4, x5, x6, x7 show very high degrees of correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_MRTW-qNP5Dn",
    "outputId": "aa4f182a-7ac8-43ae-9593-bd7f8b340071"
   },
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9qlePvMP5Dp"
   },
   "source": [
    "Let us compute the cofficient of correlation between each pair of predictors, and visualize the matrix of correlation coefficients using a heat map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1AKYEBe1P5Dx",
    "outputId": "0457f423-6528-48aa-b882-5a31e64edfbd"
   },
   "outputs": [],
   "source": [
    "# generating heat map\n",
    "sns.heatmap(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HyzrCpk0P5Dz"
   },
   "source": [
    "**Do the predictors fall naturally into groups based on the correlation values?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nbKwt-Z7P5D0"
   },
   "source": [
    "We can see that higly correlated predictors fall into dark red groups based on correlation values close to 1. Other correlation values also form differently coloured groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\">**If you were asked to select a minimal subset of predictors based on the correlation information in order to build a good regression model, how many predictors will you pick, and which ones will you choose? **</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oyle2qJFP5D0"
   },
   "source": [
    "** Your answer here **\n",
    "We may choose one predictor from the x1,x2,x3 list - let's pick x1. <br/>\n",
    "Similarly, let's pick x6 out of x4,x5,x6,x7. <br/>\n",
    "The other predictors are not strongly correlated, so we pick them all, i.e. x8,x9,x10. <br/>\n",
    "Thus, we have picked 5 predictors x1, x6, x8, x9, x10 for our regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k33gGB0LP5D1"
   },
   "source": [
    "### Model Selection Criteria: Bayesian Information Criterion (BIC)\n",
    "\n",
    "Generally BIC = -2 x Log-likehood + 2 x log(K)\n",
    "\n",
    "For least-squares regression specifically,\n",
    "\n",
    "$$BIC = n \\log \\Big(\\frac{RSS}{n}\\Big) + \\log(n)*K$$\n",
    "\n",
    "where, <br/>\n",
    "RSS = Residual Sum of Squares <br/>\n",
    "n = the number of obervations <br/>\n",
    "K = the number of features in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESjMwJc6P5D1"
   },
   "source": [
    "### Selecting minimal subset of predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ozeQZdW9P5D2"
   },
   "source": [
    "Let us apply the exhaustive search variable selection methods discussed in class to choose a minimal subset of predictors that yield high prediction accuracy. We will use the Bayesian Information Criterion (BIC) to choose the subset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_subset_of_size(x, y, num_predictors):\n",
    "    predictors = x.columns\n",
    "    \n",
    "    best_r_squared = -np.inf\n",
    "    best_model_data = None\n",
    "\n",
    "    # Enumerate subsets of the given size\n",
    "    subsets_of_size_k = itertools.combinations(predictors, num_predictors)\n",
    "\n",
    "    # Inner loop: iterate through subsets_k\n",
    "    for subset in subsets_of_size_k:\n",
    "\n",
    "        # Fit regression model using ‘subset’ and calculate R^2 \n",
    "        # Keep track of subset with highest R^2\n",
    "\n",
    "        features = list(subset)\n",
    "        x_subset = sm.add_constant(x[features])\n",
    "\n",
    "        model = sm.OLS(y, x_subset).fit()\n",
    "        r_squared = model.rsquared\n",
    "\n",
    "        # Check if we get a higher R^2 value than than current max R^2.\n",
    "        # If so, update our best subset \n",
    "        if r_squared > best_r_squared:\n",
    "            best_r_squared = r_squared\n",
    "            best_model_data = {\n",
    "                'r_squared': r_squared,\n",
    "                'subset': features,\n",
    "                'model': model\n",
    "            }\n",
    "    return best_model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_best_subset_of_size(x, y, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "acthZLgNP5D3"
   },
   "outputs": [],
   "source": [
    "def exhaustive_search_selection(x, y):\n",
    "    \"\"\"Exhaustively search predictor combinations\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : DataFrame of predictors/features\n",
    "    y : response varible \n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    -----------\n",
    "    \n",
    "    Dataframe of model comparisons and OLS Model with \n",
    "    lowest BIC for subset with highest R^2\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    predictors = x.columns\n",
    "    \n",
    "    stats = []\n",
    "    models = dict()\n",
    "    \n",
    "    # Outer loop: iterate over sizes 1, 2 .... d\n",
    "    for k in range(1, len(predictors)):\n",
    "        \n",
    "        best_size_k_model = find_best_subset_of_size(\n",
    "            x, y, num_predictors=k)\n",
    "        best_subset = best_size_k_model['subset']\n",
    "        best_model = best_size_k_model['model']\n",
    "        \n",
    "        stats.append({\n",
    "            'k': k,\n",
    "            'formula': \"y ~ {}\".format(' + '.join(best_subset)),\n",
    "            'bic': best_model.bic,\n",
    "            'r_squared': best_model.rsquared\n",
    "        })\n",
    "        models[k] = best_model\n",
    "        \n",
    "    return pd.DataFrame(stats), models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HIaZwf7YP5EF",
    "outputId": "4e431f7f-5e93-4e19-cf4a-ad76a327b1a6"
   },
   "outputs": [],
   "source": [
    "stats, models = exhaustive_search_selection(x, y)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.plot(x='k', y='bic', marker='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_stat = stats.iloc[stats.bic.idxmin()]\n",
    "best_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_k = best_stat['k']\n",
    "best_bic = best_stat['bic']\n",
    "best_formula = best_stat['formula']\n",
    "best_r2 = best_stat['r_squared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HIaZwf7YP5EF",
    "outputId": "4e431f7f-5e93-4e19-cf4a-ad76a327b1a6"
   },
   "outputs": [],
   "source": [
    "print(\"The best overall model is `{formula}` with bic={bic:.2f} and R^2={r_squared:.3f}\".format(\n",
    "    formula=best_formula, bic=best_bic, r_squared=best_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WK3ebH8dP5EH",
    "outputId": "15be5197-5186-4ee1-ea19-251deba6e1cd"
   },
   "outputs": [],
   "source": [
    "models[best_k].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5zN2PzfP5EI"
   },
   "source": [
    "**Do the chosen subsets match the ones you picked using the correlation matrix you had visualized?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2oOfNNpP5EJ"
   },
   "source": [
    "Yes! The predictor subset matches with the ones we picked before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "N0W-TBrqP5EJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6ogxoMjP5BR"
   },
   "source": [
    "## Plotting multiple axes in a single figure\n",
    "\n",
    "![](https://i.imgur.com/XTzSuoR.png)\n",
    "source: http://matplotlib.org/faq/usage_faq.html\n",
    "\n",
    "See also [this](http://matplotlib.org/faq/usage_faq.html) matplotlib tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "QAno5_o3P5Dg",
    "k33gGB0LP5D1",
    "ESjMwJc6P5D1"
   ],
   "name": "section_3_solutions.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
